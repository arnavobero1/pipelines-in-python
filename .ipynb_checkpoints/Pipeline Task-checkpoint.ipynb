{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines in Logistic Regression\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "1) Number of times pregnant\n",
    "\n",
    "2) Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "\n",
    "3) Diastolic blood pressure (mm Hg)\n",
    "\n",
    "4) Triceps skin fold thickness (mm)\n",
    "\n",
    "5) 2-Hour serum insulin (mu U/ml)\n",
    "\n",
    "6) Body mass index (weight in kg/(height in m)^2)\n",
    "\n",
    "7) Diabetes pedigree function\n",
    "\n",
    "8) Age (years)\n",
    "\n",
    "9) Class variable (0 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the necessary libraries.\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing data from CSV.\n",
    "df = pd.read_csv('diabetes.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      "Pregnancies                 768 non-null int64\n",
      "Glucose                     768 non-null int64\n",
      "BloodPressure               768 non-null int64\n",
      "SkinThickness               768 non-null int64\n",
      "Insulin                     768 non-null int64\n",
      "BMI                         768 non-null float64\n",
      "DiabetesPedigreeFunction    768 non-null float64\n",
      "Age                         768 non-null int64\n",
      "Outcome                     768 non-null int64\n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "#Checking the info for the dataframe.\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using train test split to split the data between training data and test data, in this case 25% test data and 75% training.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('Outcome',axis=1), \n",
    "                                                    df['Outcome'], test_size=0.25, \n",
    "                                                    random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the logistics regression model.\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating an instance of the model and fitting the training data into it to train our model.\n",
    "logmodel = LogisticRegression()\n",
    "logmodel.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting how are model has performed on bases of test data.\n",
    "predictions = logmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.90      0.85       124\n",
      "           1       0.76      0.62      0.68        68\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       192\n",
      "   macro avg       0.79      0.76      0.77       192\n",
      "weighted avg       0.79      0.80      0.79       192\n",
      "\n",
      "\n",
      "\n",
      "[[111  13]\n",
      " [ 26  42]]\n"
     ]
    }
   ],
   "source": [
    "#Importing and running the confusion matrix and classification report to check how our model has performed.\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(y_test,predictions))\n",
    "print('\\n')\n",
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now to make the same model using pipelines.\n",
    "#Importing the pipeline package.\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the pipeline.In this case it will consist of only one feature and that is the model itself.\n",
    "pipeline = Pipeline([\n",
    "    ('logmodel', LogisticRegression()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('logmodel', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting the training data into the pipeline.\n",
    "pipeline.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating an prediction on bases of test data for the same.\n",
    "predictions = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.90      0.85       124\n",
      "           1       0.76      0.62      0.68        68\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       192\n",
      "   macro avg       0.79      0.76      0.77       192\n",
      "weighted avg       0.79      0.80      0.79       192\n",
      "\n",
      "\n",
      "\n",
      "[[111  13]\n",
      " [ 26  42]]\n"
     ]
    }
   ],
   "source": [
    "#Checking how our model has performed using the pipeline model structure\n",
    "print(classification_report(y_test,predictions))\n",
    "print('\\n')\n",
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines in Linear Regression\n",
    "Attribute Information:\n",
    "\n",
    "1) Avg. Area Income (dollars) \n",
    "\n",
    "2) Avg. Area House Age (years)\n",
    "\n",
    "3) Avg. Area Number of Rooms \n",
    "\n",
    "4) Avg. Area Number of Bedrooms\n",
    "\n",
    "5) Area Population\n",
    "\n",
    "6) Price (dollars)\n",
    "\n",
    "7) Address\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg. Area Income</th>\n",
       "      <th>Avg. Area House Age</th>\n",
       "      <th>Avg. Area Number of Rooms</th>\n",
       "      <th>Avg. Area Number of Bedrooms</th>\n",
       "      <th>Area Population</th>\n",
       "      <th>Price</th>\n",
       "      <th>Address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79545.458574</td>\n",
       "      <td>5.682861</td>\n",
       "      <td>7.009188</td>\n",
       "      <td>4.09</td>\n",
       "      <td>23086.800503</td>\n",
       "      <td>1.059034e+06</td>\n",
       "      <td>208 Michael Ferry Apt. 674\\nLaurabury, NE 3701...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79248.642455</td>\n",
       "      <td>6.002900</td>\n",
       "      <td>6.730821</td>\n",
       "      <td>3.09</td>\n",
       "      <td>40173.072174</td>\n",
       "      <td>1.505891e+06</td>\n",
       "      <td>188 Johnson Views Suite 079\\nLake Kathleen, CA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61287.067179</td>\n",
       "      <td>5.865890</td>\n",
       "      <td>8.512727</td>\n",
       "      <td>5.13</td>\n",
       "      <td>36882.159400</td>\n",
       "      <td>1.058988e+06</td>\n",
       "      <td>9127 Elizabeth Stravenue\\nDanieltown, WI 06482...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63345.240046</td>\n",
       "      <td>7.188236</td>\n",
       "      <td>5.586729</td>\n",
       "      <td>3.26</td>\n",
       "      <td>34310.242831</td>\n",
       "      <td>1.260617e+06</td>\n",
       "      <td>USS Barnett\\nFPO AP 44820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59982.197226</td>\n",
       "      <td>5.040555</td>\n",
       "      <td>7.839388</td>\n",
       "      <td>4.23</td>\n",
       "      <td>26354.109472</td>\n",
       "      <td>6.309435e+05</td>\n",
       "      <td>USNS Raymond\\nFPO AE 09386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Avg. Area Income  Avg. Area House Age  Avg. Area Number of Rooms  \\\n",
       "0      79545.458574             5.682861                   7.009188   \n",
       "1      79248.642455             6.002900                   6.730821   \n",
       "2      61287.067179             5.865890                   8.512727   \n",
       "3      63345.240046             7.188236                   5.586729   \n",
       "4      59982.197226             5.040555                   7.839388   \n",
       "\n",
       "   Avg. Area Number of Bedrooms  Area Population         Price  \\\n",
       "0                          4.09     23086.800503  1.059034e+06   \n",
       "1                          3.09     40173.072174  1.505891e+06   \n",
       "2                          5.13     36882.159400  1.058988e+06   \n",
       "3                          3.26     34310.242831  1.260617e+06   \n",
       "4                          4.23     26354.109472  6.309435e+05   \n",
       "\n",
       "                                             Address  \n",
       "0  208 Michael Ferry Apt. 674\\nLaurabury, NE 3701...  \n",
       "1  188 Johnson Views Suite 079\\nLake Kathleen, CA...  \n",
       "2  9127 Elizabeth Stravenue\\nDanieltown, WI 06482...  \n",
       "3                          USS Barnett\\nFPO AP 44820  \n",
       "4                         USNS Raymond\\nFPO AE 09386  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing data from CSV.\n",
    "df1 = pd.read_csv('USA_Housing.csv')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 7 columns):\n",
      "Avg. Area Income                5000 non-null float64\n",
      "Avg. Area House Age             5000 non-null float64\n",
      "Avg. Area Number of Rooms       5000 non-null float64\n",
      "Avg. Area Number of Bedrooms    5000 non-null float64\n",
      "Area Population                 5000 non-null float64\n",
      "Price                           5000 non-null float64\n",
      "Address                         5000 non-null object\n",
      "dtypes: float64(6), object(1)\n",
      "memory usage: 273.5+ KB\n"
     ]
    }
   ],
   "source": [
    "#Checking the info for the dataframe.\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using train test split to split the data between training data and test data, in this case 25% test data and 75% training.\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "X_train, X_test, y_train, y_test = train_test_split(df1.drop(['Price','Address'],axis=1), \n",
    "                                                    df1['Price'], test_size=0.25, \n",
    "                                                    random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating an instance of the model and fitting the training data into it.\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting how are model has performed on bases of test data.\n",
    "predictions = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 81877.46809001848\n",
      "MSE: 10364756049.53774\n",
      "RMSE: 101807.44594349542\n"
     ]
    }
   ],
   "source": [
    "#Checking how our model has done.\n",
    "from sklearn import metrics\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now to make the same model using pipelines.\n",
    "#Creating the pipeline.In this case it will consist of only one feature and that is the model itself.\n",
    "pipeline = Pipeline([\n",
    "    ('linmodel', LinearRegression()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('linmodel', LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting the training data into the pipeline.\n",
    "pipeline.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating an prediction on bases of test data for the same.\n",
    "predictions = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 81877.46809001848\n",
      "MSE: 10364756049.53774\n",
      "RMSE: 101807.44594349542\n"
     ]
    }
   ],
   "source": [
    "#Checking how our pipeline model has done.\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines in KNN\n",
    "Attribute Information:\n",
    "\n",
    "1) WTT\n",
    "\n",
    "2) PTI\n",
    "\n",
    "3) EQW \n",
    "\n",
    "4) SBI\n",
    "\n",
    "5) LQE\n",
    "\n",
    "6) QWG\n",
    "\n",
    "7) FDJ\n",
    "\n",
    "8) PJF\n",
    "\n",
    "9) HQE\n",
    "\n",
    "10) NXJ\n",
    "\n",
    "11) Class variable (0 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WTT</th>\n",
       "      <th>PTI</th>\n",
       "      <th>EQW</th>\n",
       "      <th>SBI</th>\n",
       "      <th>LQE</th>\n",
       "      <th>QWG</th>\n",
       "      <th>FDJ</th>\n",
       "      <th>PJF</th>\n",
       "      <th>HQE</th>\n",
       "      <th>NXJ</th>\n",
       "      <th>TARGET CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.913917</td>\n",
       "      <td>1.162073</td>\n",
       "      <td>0.567946</td>\n",
       "      <td>0.755464</td>\n",
       "      <td>0.780862</td>\n",
       "      <td>0.352608</td>\n",
       "      <td>0.759697</td>\n",
       "      <td>0.643798</td>\n",
       "      <td>0.879422</td>\n",
       "      <td>1.231409</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.635632</td>\n",
       "      <td>1.003722</td>\n",
       "      <td>0.535342</td>\n",
       "      <td>0.825645</td>\n",
       "      <td>0.924109</td>\n",
       "      <td>0.648450</td>\n",
       "      <td>0.675334</td>\n",
       "      <td>1.013546</td>\n",
       "      <td>0.621552</td>\n",
       "      <td>1.492702</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.721360</td>\n",
       "      <td>1.201493</td>\n",
       "      <td>0.921990</td>\n",
       "      <td>0.855595</td>\n",
       "      <td>1.526629</td>\n",
       "      <td>0.720781</td>\n",
       "      <td>1.626351</td>\n",
       "      <td>1.154483</td>\n",
       "      <td>0.957877</td>\n",
       "      <td>1.285597</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.234204</td>\n",
       "      <td>1.386726</td>\n",
       "      <td>0.653046</td>\n",
       "      <td>0.825624</td>\n",
       "      <td>1.142504</td>\n",
       "      <td>0.875128</td>\n",
       "      <td>1.409708</td>\n",
       "      <td>1.380003</td>\n",
       "      <td>1.522692</td>\n",
       "      <td>1.153093</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.279491</td>\n",
       "      <td>0.949750</td>\n",
       "      <td>0.627280</td>\n",
       "      <td>0.668976</td>\n",
       "      <td>1.232537</td>\n",
       "      <td>0.703727</td>\n",
       "      <td>1.115596</td>\n",
       "      <td>0.646691</td>\n",
       "      <td>1.463812</td>\n",
       "      <td>1.419167</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        WTT       PTI       EQW       SBI       LQE       QWG       FDJ  \\\n",
       "0  0.913917  1.162073  0.567946  0.755464  0.780862  0.352608  0.759697   \n",
       "1  0.635632  1.003722  0.535342  0.825645  0.924109  0.648450  0.675334   \n",
       "2  0.721360  1.201493  0.921990  0.855595  1.526629  0.720781  1.626351   \n",
       "3  1.234204  1.386726  0.653046  0.825624  1.142504  0.875128  1.409708   \n",
       "4  1.279491  0.949750  0.627280  0.668976  1.232537  0.703727  1.115596   \n",
       "\n",
       "        PJF       HQE       NXJ  TARGET CLASS  \n",
       "0  0.643798  0.879422  1.231409             1  \n",
       "1  1.013546  0.621552  1.492702             0  \n",
       "2  1.154483  0.957877  1.285597             0  \n",
       "3  1.380003  1.522692  1.153093             1  \n",
       "4  0.646691  1.463812  1.419167             1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing data from CSV.\n",
    "df2 = pd.read_csv(\"Classified Data\",index_col=0)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the standardscaler and creating an instance of it.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the data into the scaler and creating its scaled features.\n",
    "scaler.fit(df2.drop('TARGET CLASS',axis=1))\n",
    "scaled_features = scaler.transform(df2.drop('TARGET CLASS',axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WTT</th>\n",
       "      <th>PTI</th>\n",
       "      <th>EQW</th>\n",
       "      <th>SBI</th>\n",
       "      <th>LQE</th>\n",
       "      <th>QWG</th>\n",
       "      <th>FDJ</th>\n",
       "      <th>PJF</th>\n",
       "      <th>HQE</th>\n",
       "      <th>NXJ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.123542</td>\n",
       "      <td>0.185907</td>\n",
       "      <td>-0.913431</td>\n",
       "      <td>0.319629</td>\n",
       "      <td>-1.033637</td>\n",
       "      <td>-2.308375</td>\n",
       "      <td>-0.798951</td>\n",
       "      <td>-1.482368</td>\n",
       "      <td>-0.949719</td>\n",
       "      <td>-0.643314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.084836</td>\n",
       "      <td>-0.430348</td>\n",
       "      <td>-1.025313</td>\n",
       "      <td>0.625388</td>\n",
       "      <td>-0.444847</td>\n",
       "      <td>-1.152706</td>\n",
       "      <td>-1.129797</td>\n",
       "      <td>-0.202240</td>\n",
       "      <td>-1.828051</td>\n",
       "      <td>0.636759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.788702</td>\n",
       "      <td>0.339318</td>\n",
       "      <td>0.301511</td>\n",
       "      <td>0.755873</td>\n",
       "      <td>2.031693</td>\n",
       "      <td>-0.870156</td>\n",
       "      <td>2.599818</td>\n",
       "      <td>0.285707</td>\n",
       "      <td>-0.682494</td>\n",
       "      <td>-0.377850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.982841</td>\n",
       "      <td>1.060193</td>\n",
       "      <td>-0.621399</td>\n",
       "      <td>0.625299</td>\n",
       "      <td>0.452820</td>\n",
       "      <td>-0.267220</td>\n",
       "      <td>1.750208</td>\n",
       "      <td>1.066491</td>\n",
       "      <td>1.241325</td>\n",
       "      <td>-1.026987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.139275</td>\n",
       "      <td>-0.640392</td>\n",
       "      <td>-0.709819</td>\n",
       "      <td>-0.057175</td>\n",
       "      <td>0.822886</td>\n",
       "      <td>-0.936773</td>\n",
       "      <td>0.596782</td>\n",
       "      <td>-1.472352</td>\n",
       "      <td>1.040772</td>\n",
       "      <td>0.276510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        WTT       PTI       EQW       SBI       LQE       QWG       FDJ  \\\n",
       "0 -0.123542  0.185907 -0.913431  0.319629 -1.033637 -2.308375 -0.798951   \n",
       "1 -1.084836 -0.430348 -1.025313  0.625388 -0.444847 -1.152706 -1.129797   \n",
       "2 -0.788702  0.339318  0.301511  0.755873  2.031693 -0.870156  2.599818   \n",
       "3  0.982841  1.060193 -0.621399  0.625299  0.452820 -0.267220  1.750208   \n",
       "4  1.139275 -0.640392 -0.709819 -0.057175  0.822886 -0.936773  0.596782   \n",
       "\n",
       "        PJF       HQE       NXJ  \n",
       "0 -1.482368 -0.949719 -0.643314  \n",
       "1 -0.202240 -1.828051  0.636759  \n",
       "2  0.285707 -0.682494 -0.377850  \n",
       "3  1.066491  1.241325 -1.026987  \n",
       "4 -1.472352  1.040772  0.276510  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a dataframe without the target class to run operations using its data.\n",
    "df_feat = pd.DataFrame(scaled_features,columns=df2.columns[:-1])\n",
    "df_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into training and test data. \n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features,df2['TARGET CLASS'],\n",
    "                                                    test_size=0.30,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing the KNN package, creating an instance of it and fitting the training data into it.\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating an prediction on bases of test data for the same.\n",
    "pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WITH K=1\n",
      "\n",
      "\n",
      "[[151   8]\n",
      " [ 15 126]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93       159\n",
      "           1       0.94      0.89      0.92       141\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       300\n",
      "   macro avg       0.92      0.92      0.92       300\n",
      "weighted avg       0.92      0.92      0.92       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Checking how our model has performed using the pipeline model structure\n",
    "# FIRST A QUICK COMPARISON TO OUR ORIGINAL K=1\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "knn.fit(X_train,y_train)\n",
    "pred = knn.predict(X_test)\n",
    "\n",
    "print('WITH K=1')\n",
    "print('\\n')\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now to make the same model using pipelines.\n",
    "#Creating the pipeline.In this case it will consist of the model itself and standardscaler.\n",
    "pipeline = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('KNN',KNeighborsClassifier(n_neighbors=1)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scale', StandardScaler(copy=True, with_mean=True, with_std=True)), ('KNN', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n",
       "           weights='uniform'))])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting the training data into the pipeline.\n",
    "pipeline.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating an prediction on bases of test data for the same.\n",
    "predictions = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WITH K=1\n",
      "\n",
      "\n",
      "[[151   8]\n",
      " [ 14 127]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93       159\n",
      "           1       0.94      0.90      0.92       141\n",
      "\n",
      "   micro avg       0.93      0.93      0.93       300\n",
      "   macro avg       0.93      0.93      0.93       300\n",
      "weighted avg       0.93      0.93      0.93       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Checking how our model has performed using the pipeline model structure\n",
    "# FIRST A QUICK COMPARISON TO OUR ORIGINAL K=1\n",
    "print('WITH K=1')\n",
    "print('\\n')\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines in SVM\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "       mean radius\n",
    "       mean texture \n",
    "       mean perimeter\n",
    "       mean area,\n",
    "       mean smoothness\n",
    "       mean compactness\n",
    "       mean concavity\n",
    "       mean concave points \n",
    "       mean symmetry\n",
    "       mean fractal dimension\n",
    "       radius error \n",
    "       texture error\n",
    "       perimeter error\n",
    "       area error\n",
    "       smoothness error\n",
    "       compactness error\n",
    "       concavity error\n",
    "       concave points error\n",
    "       symmetry error\n",
    "       fractal dimension error \n",
    "       worst radius \n",
    "       worst texture\n",
    "       worst perimeter \n",
    "       worst area \n",
    "       worst smoothness\n",
    "       worst compactness \n",
    "       worst concavity \n",
    "       worst concave points\n",
    "       worst symmetry \n",
    "       worst fractal dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the dataset from saved data.\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Since its a dictionary we check its keys.\n",
    "cancer.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 30 columns):\n",
      "mean radius                569 non-null float64\n",
      "mean texture               569 non-null float64\n",
      "mean perimeter             569 non-null float64\n",
      "mean area                  569 non-null float64\n",
      "mean smoothness            569 non-null float64\n",
      "mean compactness           569 non-null float64\n",
      "mean concavity             569 non-null float64\n",
      "mean concave points        569 non-null float64\n",
      "mean symmetry              569 non-null float64\n",
      "mean fractal dimension     569 non-null float64\n",
      "radius error               569 non-null float64\n",
      "texture error              569 non-null float64\n",
      "perimeter error            569 non-null float64\n",
      "area error                 569 non-null float64\n",
      "smoothness error           569 non-null float64\n",
      "compactness error          569 non-null float64\n",
      "concavity error            569 non-null float64\n",
      "concave points error       569 non-null float64\n",
      "symmetry error             569 non-null float64\n",
      "fractal dimension error    569 non-null float64\n",
      "worst radius               569 non-null float64\n",
      "worst texture              569 non-null float64\n",
      "worst perimeter            569 non-null float64\n",
      "worst area                 569 non-null float64\n",
      "worst smoothness           569 non-null float64\n",
      "worst compactness          569 non-null float64\n",
      "worst concavity            569 non-null float64\n",
      "worst concave points       569 non-null float64\n",
      "worst symmetry             569 non-null float64\n",
      "worst fractal dimension    569 non-null float64\n",
      "dtypes: float64(30)\n",
      "memory usage: 133.4 KB\n"
     ]
    }
   ],
   "source": [
    "#Creating a dataframe using data key and its values.\n",
    "df_feat = pd.DataFrame(cancer['data'],columns=cancer['feature_names'])\n",
    "df_feat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating another dataframe for target column which consists of ones and zeroes.\n",
    "df_target = pd.DataFrame(cancer['target'],columns=['Cancer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension           ...             worst radius  \\\n",
       "0                 0.07871           ...                    25.38   \n",
       "1                 0.05667           ...                    24.99   \n",
       "2                 0.05999           ...                    23.57   \n",
       "3                 0.09744           ...                    14.91   \n",
       "4                 0.05883           ...                    22.54   \n",
       "\n",
       "   worst texture  worst perimeter  worst area  worst smoothness  \\\n",
       "0          17.33           184.60      2019.0            0.1622   \n",
       "1          23.41           158.80      1956.0            0.1238   \n",
       "2          25.53           152.50      1709.0            0.1444   \n",
       "3          26.50            98.87       567.7            0.2098   \n",
       "4          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   worst compactness  worst concavity  worst concave points  worst symmetry  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   worst fractal dimension  \n",
       "0                  0.11890  \n",
       "1                  0.08902  \n",
       "2                  0.08758  \n",
       "3                  0.17300  \n",
       "4                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the first dataframe.\n",
    "df_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into training data and test data.\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_feat, np.ravel(df_target), test_size=0.30, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the SVC package and creating an instance of it.\n",
    "from sklearn.svm import SVC\n",
    "model = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a param_grid dictionary for the GridSeachCV.\n",
    "param_grid = {'C': [0.1,1, 10, 100, 1000], 'gamma': [1,0.1,0.01,0.001,0.0001], 'kernel': ['rbf']} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the GridSearchCV and creating an instance of it.\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV]  C=0.1, gamma=1, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV]  C=0.1, gamma=1, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV]  C=0.1, gamma=1, kernel=rbf, score=0.6363636363636364, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV]  C=0.1, gamma=0.1, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV]  C=0.1, gamma=0.1, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV]  C=0.1, gamma=0.1, kernel=rbf, score=0.6363636363636364, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV]  C=0.1, gamma=0.01, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV]  C=0.1, gamma=0.01, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV]  C=0.1, gamma=0.01, kernel=rbf, score=0.6363636363636364, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV]  C=0.1, gamma=0.001, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV]  C=0.1, gamma=0.001, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV]  C=0.1, gamma=0.001, kernel=rbf, score=0.6363636363636364, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV]  C=0.1, gamma=0.0001, kernel=rbf, score=0.9022556390977443, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV]  C=0.1, gamma=0.0001, kernel=rbf, score=0.9624060150375939, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV]  C=0.1, gamma=0.0001, kernel=rbf, score=0.9166666666666666, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV]  C=1, gamma=1, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV]  C=1, gamma=1, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV]  C=1, gamma=1, kernel=rbf, score=0.6363636363636364, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV]  C=1, gamma=0.1, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV]  C=1, gamma=0.1, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV]  C=1, gamma=0.1, kernel=rbf, score=0.6363636363636364, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV]  C=1, gamma=0.01, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV]  C=1, gamma=0.01, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV]  C=1, gamma=0.01, kernel=rbf, score=0.6363636363636364, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV]  C=1, gamma=0.001, kernel=rbf, score=0.9022556390977443, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV]  C=1, gamma=0.001, kernel=rbf, score=0.9398496240601504, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV]  C=1, gamma=0.001, kernel=rbf, score=0.9545454545454546, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV]  C=1, gamma=0.0001, kernel=rbf, score=0.9398496240601504, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV]  C=1, gamma=0.0001, kernel=rbf, score=0.9699248120300752, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV]  C=1, gamma=0.0001, kernel=rbf, score=0.946969696969697, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV]  C=10, gamma=1, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV]  C=10, gamma=1, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV]  C=10, gamma=1, kernel=rbf, score=0.6363636363636364, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV]  C=10, gamma=0.1, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV]  C=10, gamma=0.1, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV]  C=10, gamma=0.1, kernel=rbf, score=0.6363636363636364, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV]  C=10, gamma=0.01, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV]  C=10, gamma=0.01, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV]  C=10, gamma=0.01, kernel=rbf, score=0.6363636363636364, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV]  C=10, gamma=0.001, kernel=rbf, score=0.8947368421052632, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV]  C=10, gamma=0.001, kernel=rbf, score=0.9323308270676691, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV]  C=10, gamma=0.001, kernel=rbf, score=0.9166666666666666, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV]  C=10, gamma=0.0001, kernel=rbf, score=0.9323308270676691, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV]  C=10, gamma=0.0001, kernel=rbf, score=0.9699248120300752, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV]  C=10, gamma=0.0001, kernel=rbf, score=0.9621212121212122, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV]  C=100, gamma=1, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV]  C=100, gamma=1, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV]  C=100, gamma=1, kernel=rbf, score=0.6363636363636364, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV]  C=100, gamma=0.1, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV]  C=100, gamma=0.1, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV]  C=100, gamma=0.1, kernel=rbf, score=0.6363636363636364, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV]  C=100, gamma=0.01, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV]  C=100, gamma=0.01, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV]  C=100, gamma=0.01, kernel=rbf, score=0.6363636363636364, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV]  C=100, gamma=0.001, kernel=rbf, score=0.8947368421052632, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV]  C=100, gamma=0.001, kernel=rbf, score=0.9323308270676691, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV]  C=100, gamma=0.001, kernel=rbf, score=0.9166666666666666, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=100, gamma=0.0001, kernel=rbf, score=0.9172932330827067, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV]  C=100, gamma=0.0001, kernel=rbf, score=0.9774436090225563, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV]  C=100, gamma=0.0001, kernel=rbf, score=0.9393939393939394, total=   0.0s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV]  C=1000, gamma=1, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV]  C=1000, gamma=1, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV]  C=1000, gamma=1, kernel=rbf, score=0.6363636363636364, total=   0.0s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV]  C=1000, gamma=0.1, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV]  C=1000, gamma=0.1, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV]  C=1000, gamma=0.1, kernel=rbf, score=0.6363636363636364, total=   0.0s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV]  C=1000, gamma=0.01, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV]  C=1000, gamma=0.01, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV]  C=1000, gamma=0.01, kernel=rbf, score=0.6363636363636364, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV]  C=1000, gamma=0.001, kernel=rbf, score=0.8947368421052632, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV]  C=1000, gamma=0.001, kernel=rbf, score=0.9323308270676691, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV]  C=1000, gamma=0.001, kernel=rbf, score=0.9166666666666666, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV]  C=1000, gamma=0.0001, kernel=rbf, score=0.9097744360902256, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV]  C=1000, gamma=0.0001, kernel=rbf, score=0.9699248120300752, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV]  C=1000, gamma=0.0001, kernel=rbf, score=0.9318181818181818, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    1.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'C': [0.1, 1, 10, 100, 1000], 'gamma': [1, 0.1, 0.01, 0.001, 0.0001], 'kernel': ['rbf']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=3)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting the data into the model.\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting off test data.\n",
    "grid_predictions = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 60   6]\n",
      " [  3 102]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93        66\n",
      "           1       0.94      0.97      0.96       105\n",
      "\n",
      "   micro avg       0.95      0.95      0.95       171\n",
      "   macro avg       0.95      0.94      0.94       171\n",
      "weighted avg       0.95      0.95      0.95       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Seeing how our model has done.\n",
    "print(confusion_matrix(y_test,grid_predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,grid_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now to make the same model using pipelines.\n",
    "#Creating the pipeline.In this case it will consist of GridSeachCV.\n",
    "pipeline = Pipeline([\n",
    "    ('CV',GridSearchCV(SVC(),param_grid,refit=True,verbose=3)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV]  C=0.1, gamma=1, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV]  C=0.1, gamma=1, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV]  C=0.1, gamma=1, kernel=rbf, score=0.6363636363636364, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV]  C=0.1, gamma=0.1, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV]  C=0.1, gamma=0.1, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV]  C=0.1, gamma=0.1, kernel=rbf, score=0.6363636363636364, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV]  C=0.1, gamma=0.01, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV]  C=0.1, gamma=0.01, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV]  C=0.1, gamma=0.01, kernel=rbf, score=0.6363636363636364, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV]  C=0.1, gamma=0.001, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV]  C=0.1, gamma=0.001, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV]  C=0.1, gamma=0.001, kernel=rbf, score=0.6363636363636364, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV]  C=0.1, gamma=0.0001, kernel=rbf, score=0.9022556390977443, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV]  C=0.1, gamma=0.0001, kernel=rbf, score=0.9624060150375939, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV]  C=0.1, gamma=0.0001, kernel=rbf, score=0.9166666666666666, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV]  C=1, gamma=1, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV]  C=1, gamma=1, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV]  C=1, gamma=1, kernel=rbf, score=0.6363636363636364, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV]  C=1, gamma=0.1, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV]  C=1, gamma=0.1, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV]  C=1, gamma=0.1, kernel=rbf, score=0.6363636363636364, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV]  C=1, gamma=0.01, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV]  C=1, gamma=0.01, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV]  C=1, gamma=0.01, kernel=rbf, score=0.6363636363636364, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV]  C=1, gamma=0.001, kernel=rbf, score=0.9022556390977443, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV]  C=1, gamma=0.001, kernel=rbf, score=0.9398496240601504, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV]  C=1, gamma=0.001, kernel=rbf, score=0.9545454545454546, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV]  C=1, gamma=0.0001, kernel=rbf, score=0.9398496240601504, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV]  C=1, gamma=0.0001, kernel=rbf, score=0.9699248120300752, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV]  C=1, gamma=0.0001, kernel=rbf, score=0.946969696969697, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV]  C=10, gamma=1, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV]  C=10, gamma=1, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV]  C=10, gamma=1, kernel=rbf, score=0.6363636363636364, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV]  C=10, gamma=0.1, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV]  C=10, gamma=0.1, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV]  C=10, gamma=0.1, kernel=rbf, score=0.6363636363636364, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV]  C=10, gamma=0.01, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV]  C=10, gamma=0.01, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV]  C=10, gamma=0.01, kernel=rbf, score=0.6363636363636364, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV]  C=10, gamma=0.001, kernel=rbf, score=0.8947368421052632, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV]  C=10, gamma=0.001, kernel=rbf, score=0.9323308270676691, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV]  C=10, gamma=0.001, kernel=rbf, score=0.9166666666666666, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV]  C=10, gamma=0.0001, kernel=rbf, score=0.9323308270676691, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV]  C=10, gamma=0.0001, kernel=rbf, score=0.9699248120300752, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV]  C=10, gamma=0.0001, kernel=rbf, score=0.9621212121212122, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV]  C=100, gamma=1, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV]  C=100, gamma=1, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV]  C=100, gamma=1, kernel=rbf, score=0.6363636363636364, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV]  C=100, gamma=0.1, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV]  C=100, gamma=0.1, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV]  C=100, gamma=0.1, kernel=rbf, score=0.6363636363636364, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV]  C=100, gamma=0.01, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV]  C=100, gamma=0.01, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV]  C=100, gamma=0.01, kernel=rbf, score=0.6363636363636364, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV]  C=100, gamma=0.001, kernel=rbf, score=0.8947368421052632, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV]  C=100, gamma=0.001, kernel=rbf, score=0.9323308270676691, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV]  C=100, gamma=0.001, kernel=rbf, score=0.9166666666666666, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV]  C=100, gamma=0.0001, kernel=rbf, score=0.9172932330827067, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV]  C=100, gamma=0.0001, kernel=rbf, score=0.9774436090225563, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV]  C=100, gamma=0.0001, kernel=rbf, score=0.9393939393939394, total=   0.0s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV]  C=1000, gamma=1, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=1000, gamma=1, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV]  C=1000, gamma=1, kernel=rbf, score=0.6363636363636364, total=   0.0s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV]  C=1000, gamma=0.1, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV]  C=1000, gamma=0.1, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV]  C=1000, gamma=0.1, kernel=rbf, score=0.6363636363636364, total=   0.0s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV]  C=1000, gamma=0.01, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV]  C=1000, gamma=0.01, kernel=rbf, score=0.631578947368421, total=   0.0s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV]  C=1000, gamma=0.01, kernel=rbf, score=0.6363636363636364, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV]  C=1000, gamma=0.001, kernel=rbf, score=0.8947368421052632, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV]  C=1000, gamma=0.001, kernel=rbf, score=0.9323308270676691, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV]  C=1000, gamma=0.001, kernel=rbf, score=0.9166666666666666, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV]  C=1000, gamma=0.0001, kernel=rbf, score=0.9097744360902256, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV]  C=1000, gamma=0.0001, kernel=rbf, score=0.9699248120300752, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV]  C=1000, gamma=0.0001, kernel=rbf, score=0.9318181818181818, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    1.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('CV', GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, to...   pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=3))])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting the training data into the pipeline.\n",
    "pipeline.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating an prediction on bases of test data for the same.\n",
    "predictions = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 60   6]\n",
      " [  3 102]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93        66\n",
      "           1       0.94      0.97      0.96       105\n",
      "\n",
      "   micro avg       0.95      0.95      0.95       171\n",
      "   macro avg       0.95      0.94      0.94       171\n",
      "weighted avg       0.95      0.95      0.95       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Seeing how our pipeline model has done.\n",
    "print(confusion_matrix(y_test,grid_predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,grid_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines in NLP\n",
    "\n",
    "Attribute Information:\n",
    "Messages are classified on the basis of ham or spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the nltk library.\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the data.\n",
    "messages = [line.rstrip() for line in open('SMSSpamCollection')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ham\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
      "\n",
      "\n",
      "1 ham\tOk lar... Joking wif u oni...\n",
      "\n",
      "\n",
      "2 spam\tFree entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Reading the data in a comprehendible method.\n",
    "for message_no, message in enumerate(messages[:3]):\n",
    "    print(message_no, message)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the data in the form of a dataframe.\n",
    "messages = pd.read_csv('SMSSpamCollection', sep='\\t',\n",
    "                           names=[\"label\", \"message\"])\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  length\n",
       "0   ham  Go until jurong point, crazy.. Available only ...     111\n",
       "1   ham                      Ok lar... Joking wif u oni...      29\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     155\n",
       "3   ham  U dun say so early hor... U c already then say...      49\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...      61"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adding another column to help check the length of message.\n",
    "messages['length'] = messages['message'].apply(len)\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing the stopwords and seeing the first ten.\n",
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a function to tokenise the message.\n",
    "import string\n",
    "def text_process(mess):\n",
    "    \n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove all punctuation\n",
    "    2. Remove all stopwords\n",
    "    3. Returns a list of the cleaned text\n",
    "    \"\"\"\n",
    "    nopunc = [char for char in mess if char not in string.punctuation]\n",
    "\n",
    "    nopunc = ''.join(nopunc)\n",
    "    \n",
    "    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We have the messages as lists of tokens and  we need to convert each of those messages into a vector.\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating an instance of the CountVectorizer.\n",
    "bow_transformer = CountVectorizer(analyzer=text_process).fit(messages['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11425\n"
     ]
    }
   ],
   "source": [
    "#Printing the number of words there were in all the messages.\n",
    "print(len(bow_transformer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U dun say so early hor... U c already then say...\n"
     ]
    }
   ],
   "source": [
    "#Creating a side data to see if our model works well or not, so we take a message and put it into the transformer. \n",
    "message4 = messages['message'][3]\n",
    "print(message4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 4068)\t2\n",
      "  (0, 4629)\t1\n",
      "  (0, 5261)\t1\n",
      "  (0, 6204)\t1\n",
      "  (0, 6222)\t1\n",
      "  (0, 7186)\t1\n",
      "  (0, 9554)\t2\n",
      "(1, 11425)\n"
     ]
    }
   ],
   "source": [
    "#Putting the message into the transformer to vectorise it.\n",
    "bow4 = bow_transformer.transform([message4])\n",
    "print(bow4)\n",
    "print(bow4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U\n",
      "say\n"
     ]
    }
   ],
   "source": [
    "#Checking out 2 of the vectors.\n",
    "print(bow_transformer.get_feature_names()[4068])\n",
    "print(bow_transformer.get_feature_names()[9554])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will vectorise the whole messages column.\n",
    "messages_bow = bow_transformer.transform(messages['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Sparse Matrix:  (5572, 11425)\n",
      "Amount of Non-Zero occurences:  50548\n"
     ]
    }
   ],
   "source": [
    "#Printing out the shape of the sparse matrix and amount of non-zero occurences.\n",
    "print('Shape of Sparse Matrix: ', messages_bow.shape)\n",
    "print('Amount of Non-Zero occurences: ', messages_bow.nnz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 9554)\t0.5385626262927564\n",
      "  (0, 7186)\t0.4389365653379857\n",
      "  (0, 6222)\t0.3187216892949149\n",
      "  (0, 6204)\t0.29953799723697416\n",
      "  (0, 5261)\t0.29729957405868723\n",
      "  (0, 4629)\t0.26619801906087187\n",
      "  (0, 4068)\t0.40832589933384067\n"
     ]
    }
   ],
   "source": [
    "#Now to check the term frequency and inverted document frequency we import TdidfTransformer.\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer = TfidfTransformer().fit(messages_bow)\n",
    "tfidf4 = tfidf_transformer.transform(bow4)\n",
    "print(tfidf4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2800524267409408\n",
      "8.527076498901426\n"
     ]
    }
   ],
   "source": [
    "#Checking the idf of any two words.\n",
    "print(tfidf_transformer.idf_[bow_transformer.vocabulary_['u']])\n",
    "print(tfidf_transformer.idf_[bow_transformer.vocabulary_['university']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 11425)\n"
     ]
    }
   ],
   "source": [
    "#Fitting the vectorised message into the tfidf transformer and then checking its shape.\n",
    "messages_tfidf = tfidf_transformer.transform(messages_bow)\n",
    "print(messages_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now to train our model we use Naive Bayes model and fit the data from the tdidf transformer.\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "spam_detect_model = MultinomialNB().fit(messages_tfidf, messages['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ham' 'ham' 'spam' ... 'ham' 'ham' 'ham']\n"
     ]
    }
   ],
   "source": [
    "#Creating an instinct of prediction and predicting it.\n",
    "all_predictions = spam_detect_model.predict(messages_tfidf)\n",
    "print(all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      1.00      0.99      4825\n",
      "        spam       1.00      0.85      0.92       747\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      5572\n",
      "   macro avg       0.99      0.92      0.95      5572\n",
      "weighted avg       0.98      0.98      0.98      5572\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Checking how our model has done.\n",
    "from sklearn.metrics import classification_report\n",
    "print (classification_report(messages['label'], all_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4457 1115 5572\n"
     ]
    }
   ],
   "source": [
    "#Now to work the same with pipelines we first split the data into training data and test data where message is like X and label is y.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "msg_train, msg_test, label_train, label_test = \\\n",
    "train_test_split(messages['message'], messages['label'], test_size=0.2)\n",
    "\n",
    "print(len(msg_train), len(msg_test), len(msg_train) + len(msg_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the pipeline involving all the features which are CountVectorizer and Tdidf tranformer and the model which is Naive Bayes.\n",
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=text_process)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('classifier', MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('bow', CountVectorizer(analyzer=<function text_process at 0x0000020963F741E0>,\n",
       "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
       "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
       "        max_features=None, min_df=1, ngram_range=(1, 1), preprocesso...f=False, use_idf=True)), ('classifier', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting the training data into the pipeline.\n",
    "pipeline.fit(msg_train,label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the predictions using test data.\n",
    "predictions = pipeline.predict(msg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       1.00      0.96      0.98      1011\n",
      "        spam       0.73      1.00      0.84       104\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      1115\n",
      "   macro avg       0.86      0.98      0.91      1115\n",
      "weighted avg       0.97      0.97      0.97      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Checking how our model has performed.\n",
    "print(classification_report(predictions,label_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
